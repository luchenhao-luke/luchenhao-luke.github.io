<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Luke's Blog | Luke's Blog</title><meta name="author" content="Luke"><meta name="copyright" content="Luke"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="2024&#x2F;06&#x2F;29数据准备gzip 是一种文件压缩格式，用于减小文件大小。 JSON 是一种文本格式，用于表示结构化数据。 JSON Lines (JSONL) 是一种文件格式，每行为一个独立的 JSON 对象，适合大型数据集的处理。 Dolma数据：https:&#x2F;&#x2F;github.com&#x2F;allenai&#x2F;dolma 原始语料：一般是 jsonl 格式文件，以 gz 等形式压缩 2419个gz压缩">
<meta property="og:type" content="article">
<meta property="og:title" content="Luke&#39;s Blog">
<meta property="og:url" content="http://example.com/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Luke&#39;s Blog">
<meta property="og:description" content="2024&#x2F;06&#x2F;29数据准备gzip 是一种文件压缩格式，用于减小文件大小。 JSON 是一种文本格式，用于表示结构化数据。 JSON Lines (JSONL) 是一种文件格式，每行为一个独立的 JSON 对象，适合大型数据集的处理。 Dolma数据：https:&#x2F;&#x2F;github.com&#x2F;allenai&#x2F;dolma 原始语料：一般是 jsonl 格式文件，以 gz 等形式压缩 2419个gz压缩">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar1.JPG">
<meta property="article:published_time" content="2024-06-29T09:21:38.427Z">
<meta property="article:modified_time" content="2024-08-22T07:28:11.715Z">
<meta property="article:author" content="Luke">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar1.JPG"><link rel="shortcut icon" href="/img/avatar2.JPG"><link rel="canonical" href="http://example.com/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Luke\'s Blog',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-22 15:28:11'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar1.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/background.jpeg')"><nav id="nav"><span id="blog-info"><a href="/" title="Luke's Blog"><span class="site-name">Luke's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">无题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-06-29T09:21:38.427Z" title="发表于 2024-06-29 17:21:38">2024-06-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-22T07:28:11.715Z" title="更新于 2024-08-22 15:28:11">2024-08-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="2024-06-29"><a href="#2024-06-29" class="headerlink" title="2024/06/29"></a>2024/06/29</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p><strong>gzip</strong> 是一种文件压缩格式，用于减小文件大小。</p>
<p><strong>JSON</strong> 是一种文本格式，用于表示结构化数据。</p>
<p><strong>JSON Lines (JSONL)</strong> 是一种文件格式，每行为一个独立的 JSON 对象，适合大型数据集的处理。</p>
<p>Dolma数据：<a target="_blank" rel="noopener" href="https://github.com/allenai/dolma">https://github.com/allenai/dolma</a></p>
<p>原始语料：一般是 jsonl 格式文件，以 gz 等形式压缩</p>
<p>2419个gz压缩文件</p>
<p><img src="/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/截屏2024-06-29 17.25.12.png" alt="截屏2024-06-29 17.25.12"></p>
<figure class="highlight python"><figcaption><span>scripts/make_wikipedia.py \</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python scripts/make_wikipedia.py \</span><br><span class="line">  --output wikipedia \</span><br><span class="line">  --date <span class="number">20240501</span> \</span><br><span class="line">  --lang simple \</span><br><span class="line">  --processes <span class="number">32</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>nproc</code>查看cpu核数，可根据此调整processes，一般为倍数</p>
</blockquote>
<p>生成的wiki文本中的格式如下(wiki_00.gz解压缩之后的文件)：</p>
<p>{“id”: “109”, “source”: “wikipedia”, “version”: “v0”, “text”: “Compound\n\n<templatestyles src="\"Dmbox/styles.css\"">“, “created”: “2024-05-01T00:00:00.000Z”, “added”: “2024-06-29T09:31:09.415Z”, “metadata”: {“revid”: “5040874”, “url”: “<a target="_blank" rel="noopener" href="https://simple.wikipedia.org/wiki?curid=109">https://simple.wikipedia.org/wiki?curid=109</a>“, “length”: 12}}</templatestyles></p>
<p>…</p>
<p>{“id”: “93”, “source”: “wikipedia”, “version”: “v0”, “text”: “Boil\n\nBoil might mean:\n<templatestyles src="\"Dmbox/styles.css\"">“, “created”: “2024-05-01T00:00:00.000Z”, “added”: “2024-06-29T09:31:09.415Z”, “metadata”: {“revid”: “170917”, “url”: “<a target="_blank" rel="noopener" href="https://simple.wikipedia.org/wiki?curid=93">https://simple.wikipedia.org/wiki?curid=93</a>“, “length”: 16}}</templatestyles></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dolma tag \</span><br><span class="line">    --documents &quot;wikipedia/v0/documents/*&quot; \</span><br><span class="line">    --experiment exp \</span><br><span class="line">    --taggers random_number_v1 \</span><br><span class="line">              cld2_en_paragraph_with_doc_score_v2 \</span><br><span class="line">              ft_lang_id_en_paragraph_with_doc_score_v2 \</span><br><span class="line">              char_length_with_paragraphs_v1 \</span><br><span class="line">              whitespace_tokenizer_with_paragraphs_v1 \</span><br><span class="line">    --processes 32</span><br></pre></td></tr></table></figure>
<h3 id="dedupelicate"><a href="#dedupelicate" class="headerlink" title="dedupelicate"></a>dedupelicate</h3><p>该 <code>dedupe</code> 命令使用 Bloom 过滤器在属性或段落级别对一组文档进行重复数据删除。</p>
<h2 id="2024-07-02"><a href="#2024-07-02" class="headerlink" title="2024/07/02"></a>2024/07/02</h2><ul>
<li>bash脚本下载dolma v1.7的数据集</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #!/bin/bash</span></span><br><span class="line"><span class="comment"># DATA_DIR=&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line"><span class="comment"># PARALLEL_DOWNLOADS=&quot;16&quot;</span></span><br><span class="line"><span class="comment"># DOLMA_VERSION=&quot;v1_7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># git clone https://huggingface.co/datasets/allenai/dolma</span></span><br><span class="line"><span class="comment"># mkdir -p &quot;$&#123;DATA_DIR&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat &quot;dolma/urls/$&#123;DOLMA_VERSION&#125;.txt&quot; | xargs -n 1 -P &quot;$&#123;PARALLEL_DOWNLOADS&#125;&quot; wget -q -P &quot;$DATA_DIR&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置变量</span></span><br><span class="line">DATA_DIR=<span class="string">&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line">PARALLEL_DOWNLOADS=<span class="string">&quot;16&quot;</span></span><br><span class="line">DOLMA_VERSION=<span class="string">&quot;v1_7&quot;</span></span><br><span class="line">LOG_FILE=<span class="string">&quot;download_dolma.log&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 克隆 Dolma 数据集的存储库</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/allenai/dolma</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据目录，如果目录不存在的话</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$&#123;DATA_DIR&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从指定版本的 URL 文件中读取 URL 并使用 wget 断点续传并显示进度到数据目录</span></span><br><span class="line"><span class="built_in">cat</span> <span class="string">&quot;dolma/urls/<span class="variable">$&#123;DOLMA_VERSION&#125;</span>.txt&quot;</span> | xargs -n 1 -P <span class="string">&quot;<span class="variable">$&#123;PARALLEL_DOWNLOADS&#125;</span>&quot;</span> wget -c --progress=bar:force -P <span class="string">&quot;<span class="variable">$DATA_DIR</span>&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x download_dolma.sh</span><br><span class="line">$ ./download_dolma.sh</span><br></pre></td></tr></table></figure>
<ul>
<li>bash脚本校验本地下载完的dolma数据文件和远程dolma数据文件的大小是否相同</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地文件目录</span></span><br><span class="line">local_dir=<span class="string">&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL 文件</span></span><br><span class="line">url_file=<span class="string">&quot;/home/luchenhao/dolma/urls/v1_7.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 url.txt 中的每一行</span></span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r url; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 获取文件名</span></span><br><span class="line">    filename=$(<span class="built_in">basename</span> <span class="string">&quot;<span class="variable">$url</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查远程文件大小</span></span><br><span class="line">    remote_size=$(wget --spider <span class="string">&quot;<span class="variable">$url</span>&quot;</span> 2&gt;&amp;1 | grep Length | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查命令是否成功</span></span><br><span class="line">    <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Failed to check remote file: <span class="variable">$url</span>&quot;</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取本地文件大小（以字节为单位）</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        local_size=$(<span class="built_in">du</span> -b <span class="string">&quot;<span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span> | <span class="built_in">cut</span> -f1)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Local file does not exist: <span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将本地文件大小和远程文件大小进行比较</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$remote_size</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$local_size</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;File sizes match for <span class="variable">$filename</span>: <span class="variable">$local_size</span> bytes&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;File size mismatch for <span class="variable">$filename</span>: local = <span class="variable">$local_size</span> bytes, remote = <span class="variable">$remote_size</span> bytes&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span> &lt; <span class="string">&quot;<span class="variable">$url_file</span>&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x check_file_sizes.sh</span><br><span class="line">$ ./check_file_sizes.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">File sizes match for cc_en_tail-0443.json.gz: 2568154213 bytes</span><br><span class="line">File sizes match for cc_en_tail-0444.json.gz: 2035889640 bytes</span><br><span class="line">File size mismatch for cc_news-0000.json.gz: local = 5329144093 bytes, remote = 3531963035 bytes</span><br><span class="line">File size mismatch for cc_news-0001.json.gz: local = 4444522614 bytes, remote = 3708288860 bytes</span><br><span class="line">File sizes match for cc_news-0002.json.gz: 3635572395 bytes</span><br><span class="line">File sizes match for cc_news-0003.json.gz: 3726881590 bytes</span><br><span class="line">File sizes match for cc_news-0004.json.gz: 3103556433 bytes</span><br><span class="line">File size mismatch for cc_news-0000.json.gz: local = 5329144093 bytes, remote = 3526498093 bytes</span><br><span class="line">File size mismatch for cc_news-0001.json.gz: local = 4444522614 bytes, remote = 3610880124 bytes</span><br><span class="line">File size mismatch for cc_news-0002.json.gz: local = 3635572395 bytes, remote = 1166286610 bytes</span><br><span class="line">File size mismatch for cc_news-0000.json.gz: local = 5329144093 bytes, remote = 3358108366 bytes</span><br><span class="line">File sizes match for falcon-0000.json.gz: 1795372067 bytes</span><br><span class="line">File sizes match for falcon-0001.json.gz: 1817261729 bytes</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./check_file_sizes.sh &gt; check_file_sizes.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<h2 id="docker配置"><a href="#docker配置" class="headerlink" title="docker配置"></a>docker配置</h2><ul>
<li>创建</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">docker login 10.200.88.53</span><br><span class="line"></span><br><span class="line">docker pull 10.200.88.53/luchenhao-zhejianglab.com/ragllm:v1.0</span><br><span class="line">docker run -itd --gpus all --hostname=Olmo_8xA100 --shm-size=64g -v /mnt/nas_v2/dolma_v1_7:/root/datasets/dolma_v1_7 -p 28022:22 -p 28088:8888 -p 28080:8080 --name luchenhao_v1 10.200.88.53/luchenhao-zhejianglab.com/ragllm:v1.0 /bin/zsh</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">docker run -it --gpus all --hostname=Olmo_8xA100 --shm-size=64g -v /mnt/nas_v2/dolma_v1_7:/root/datasets/dolma_v1_7 -p 18022:22 -p 18080:8080 -p 18088:8888 --name olmo_lch 10.200.88.53/luchenhao-zhejianglab.com/qwen:v0.4</span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao2 --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 48022:22 -p 48080:8080 -p 48088:8888 -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 58022:22 -p 58080:8080 -p 58088:8888 nvidia/cuda:12.1.0-base-ubuntu22.04</span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 18022:22 -p 18080:8080 -p 18088:8888 -v /mnt_llm:/mnt_llm 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.4</span><br><span class="line"></span><br><span class="line">docker exec -it luchenhao bash</span><br><span class="line"></span><br><span class="line">进入自己的docker</span><br><span class="line">执行命令：apt-get update（更新docker的apt命令）</span><br><span class="line">执行命令：apt-get install ssh（安装ssh）</span><br><span class="line">执行命令：vim /etc/ssh/sshd_config（查询ssh配置）</span><br><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line">#填加以下内容：</span><br><span class="line">Port 22</span><br><span class="line">PermitRootLogin yes #允许root用户使用ssh登录</span><br><span class="line"></span><br><span class="line">/etc/init.d/ssh restart</span><br><span class="line"></span><br><span class="line">passwd</span><br><span class="line"></span><br><span class="line">ssh root@10.5.30.42 -p 58022</span><br><span class="line"></span><br><span class="line">docker commit -a &quot;luchenhao&quot; luchenhao 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.1</span><br><span class="line">docker push 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.1</span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 58022:22 -p 58080:8080 -p 58088:8888 -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.2</span><br><span class="line"># 拉取 nvidia/cuda:12.3.0-base-ubuntu22.04 镜像创建一个名为 olmo 的容器</span><br><span class="line"># 不使用 --gpus 会导致镜像无法识别显卡</span><br><span class="line"># SCRATCH_DIR 为训练输出文件位置</span><br><span class="line"></span><br><span class="line">docker run -itd --gpus all --hostname=Olmo_4xA40 --shm-size=64g -v /mnt:/root/datasets -p 18022:22 -p 18080:8080 -p 18088:8888 --name olmo_lch 10.200.88.53/luchenhao-zhejianglab.com/qwen:v0.4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker exec -it luchenhao bash</span><br><span class="line"></span><br><span class="line">curl http://10.200.48.108:28022</span><br><span class="line"></span><br><span class="line">docker stats</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 打镜像</span><br><span class="line">docker run -itd --gpus all --hostname=Olmo_8xH100 --shm-size=32g --name OLMO 10.200.88.53/luchenhao-zhejianglab.com/ragllm:v1.0 /bin/bash</span><br><span class="line">docker exec -it OLMO bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao3 --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 38022:22 -p 38080:8080 -p 38088:8888 -v /usr/local/cuda:/usr/local/cuda -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao_v3 --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 38022:22 -p 38080:8080 -p 38088:8888 -v /data1/luchenhao:/data1/luchenhao -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run --name luchenhao_eval -itd -v /data1/luchenhao:/data1/luchenhao -v /mnt/nas_v2:/mnt --gpus all --shm-size 64G -p 48022:22 -p 48080:8080 -p 48088:8888 opencompass:v6 /bin/bash </span><br><span class="line">docker exec -it luchenhao_eval /bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name luchenhao_v4 --gpus all --hostname=Olmo_4xA40 --shm-size=64g -p 48022:22 -p 48080:8080 -p 48088:8888 -p 48000:8000 -v /usr/local/cuda:/usr/local/cuda12 -v /data1/luchenhao:/data1/luchenhao -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v0.9</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name LLamaFactory --gpus all --hostname=8xH100 --shm-size=64g -p 26022:22 -v /mnt/nas_v2:/mnt 10.200.88.53/luchenhao-zhejianglab.com/olmo:v1.0</span><br></pre></td></tr></table></figure>
<ul>
<li>存储</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop luchenhao_v2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/volume2/<span class="number">2</span>/common/public/dataset</span><br><span class="line">mount -t nfs luchenhao_nas:/volume2/<span class="number">2</span>/common/public/dataset /luchenhao_datasets</span><br><span class="line">/volume2/<span class="number">2</span>/common/public/dataset/HC3</span><br><span class="line">mount -t nfs luchenhao_nas:/volume2/<span class="number">2</span>/common/public/dataset/HC3 /luchenhao_datasets</span><br><span class="line"></span><br><span class="line">sudo mount -t nfs <span class="number">10.15</span><span class="number">.35</span><span class="number">.70</span>:/volume2/<span class="number">2</span>/common/public/dataset/HC3 /mnt/luchenhao</span><br></pre></td></tr></table></figure>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python make_wiki.py \</span><br><span class="line">  --output wikipedia \</span><br><span class="line">  --date 20240501 \</span><br><span class="line">  --lang simple \</span><br><span class="line">  --processes 32</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">dolma tag \</span><br><span class="line">    --taggers random_number_v1 \</span><br><span class="line">    --documents &quot;wikipedia/v0/documents/*&quot; \</span><br><span class="line">    --processes 16</span><br><span class="line">    </span><br><span class="line">dolma tag \</span><br><span class="line">    --experiment sample \</span><br><span class="line">    --documents &quot;wikipedia/v0/documents/*&quot; \</span><br><span class="line">    --taggers random_number_v1 \</span><br><span class="line">              cld2_en_paragraph_with_doc_score_v2 \</span><br><span class="line">              char_length_with_paragraphs_v1 \</span><br><span class="line">              whitespace_tokenizer_with_paragraphs_v1 \</span><br><span class="line">    --processes 16</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">dolma tokens \</span><br><span class="line">    --documents &quot;wikipedia/example0/documents/*.gz&quot; \</span><br><span class="line">    --tokenizer.name_or_path &quot;gpt2&quot; \</span><br><span class="line">    --destination wikipedia/example0/tokens \</span><br><span class="line">    --processes 16</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">有一个json.gz文件，里面的数据存储形式如下，每个样本的存储形式是A，如何将这个json.gz文件中的每一个样本转换成B格式？</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;id&quot;: 1,</span><br><span class="line">        &quot;uniqueKey&quot;: &quot;25c6b97fceef629cd4abca434fc9cddc&quot;,</span><br><span class="line">        &quot;titleUkey&quot;: &quot;7a8b0dd07fda2de10f5ddd50d4c0552a&quot;,</span><br><span class="line">        &quot;dataType&quot;: &quot;科技&quot;,</span><br><span class="line">        &quot;title&quot;: &quot;美团王兴发内部信：王慧文将退出公司具体管理事务&quot;,</span><br><span class="line">        &quot;content&quot;: &quot;网易科技讯1月20日消息，今日美团创始人CEO王兴给全体员工发了一封内部信。&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;id&quot;: 2,</span><br><span class="line">        &quot;uniqueKey&quot;: &quot;d82e7009646e4652d55d10c6cd113d8b&quot;,</span><br><span class="line">        &quot;titleUkey&quot;: &quot;7aa60c892a9177b94004a6857ff11fa2&quot;,</span><br><span class="line">        &quot;dataType&quot;: &quot;国际&quot;,</span><br><span class="line">        &quot;title&quot;: &quot;特朗普弹劾“大戏”进入下半场 激烈交锋正在上演&quot;,</span><br><span class="line">        &quot;content&quot;: &quot;原标题：特朗普弹劾“大戏”进入下半场一场激烈交锋正在上演1月15日，美众议院将弹劾总统条款文件呈交参议院。新华社发 美国国会参议院计划本周正式对总统特朗普弹劾案展开审理。 &quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">A:  &#123;</span><br><span class="line">        &quot;id&quot;: 2,</span><br><span class="line">        &quot;uniqueKey&quot;: &quot;d82e7009646e4652d55d10c6cd113d8b&quot;,</span><br><span class="line">        &quot;titleUkey&quot;: &quot;7aa60c892a9177b94004a6857ff11fa2&quot;,</span><br><span class="line">        &quot;dataType&quot;: &quot;国际&quot;,</span><br><span class="line">        &quot;title&quot;: &quot;特朗普弹劾“大戏”进入下半场 激烈交锋正在上演&quot;,</span><br><span class="line">        &quot;content&quot;: &quot;原标题：特朗普弹劾“大戏”进入下半场一场激烈交锋正在上演1月15日，美众议院将弹劾总统条款文件呈交参议院。新华社发 美国国会参议院计划本周正式对总统特朗普弹劾案展开审理。 &quot;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">B:   &#123;</span><br><span class="line">    &quot;id&quot;: &quot;...&quot;,             # MANDATORY: source-specific identifier</span><br><span class="line">    &quot;text&quot;: &quot;foo&quot;,           # MANDATORY: textual content of the document</span><br><span class="line">    &quot;source&quot;: &quot;...&quot;,         # MANDATORY: source of the data, such as peS2o, common-crawl, etc.</span><br><span class="line">    &quot;added&quot;: &quot;...&quot;,          # OPTIONAL: timestamp ai2 acquired this data</span><br><span class="line">    &quot;created&quot;: &quot;...&quot;         # OPTIONAL: timestamp when orig document was created (best-guess if not available)</span><br><span class="line">    &quot;metadata&quot;: &#123;...&#125;        # OPTIONAL: source-specific metadata</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/root/miniconda3/envs/dolma/lib/python3.10/site-packages/dolma/taggers</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">history | grep ossutil</span><br><span class="line"></span><br><span class="line">ossutil ls oss://zhongziban/datasets/\WuDao</span><br><span class="line"></span><br><span class="line">10B的中文</span><br><span class="line">80B的英文</span><br><span class="line">	40B的CC</span><br><span class="line">  </span><br><span class="line"> <span class="number">126.4</span>MB的json.gz、 <span class="number">568.00</span> MB的npy文件 、大约是<span class="number">0.15</span>B的tokens</span><br><span class="line"></span><br><span class="line">total_tokens = total_bytes / bytes_per_token</span><br><span class="line"></span><br><span class="line">File size <span class="keyword">for</span> 100B tokens (int32): <span class="number">372.53</span> GB</span><br><span class="line">File size <span class="keyword">for</span> 100B tokens (int64): <span class="number">745.06</span> GB</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分超大数据集</span></span><br><span class="line">split -l <span class="number">1000000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/ChinaNews-cn/part-006853-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/ChinaNews-cn/part-006853-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/ChinaNews1_cn_split_</span><br><span class="line"></span><br><span class="line">split -l <span class="number">1000000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/ChinaNews-cn/part-008323-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/ChinaNews-cn/part-008323-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/ChinaNews2_cn_split_</span><br><span class="line"></span><br><span class="line">split -l <span class="number">1000000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/Exam-cn/part-003756-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/Exam-cn/part-003756-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/Exam_cn_split_</span><br><span class="line"></span><br><span class="line">split -l <span class="number">1000000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-000036-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-000036-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/WebText1_cn_split_</span><br><span class="line"></span><br><span class="line">ossutil cp -r /mnt/nas_v2/LLM-pretrain-dataset/MNBVC oss://zhongziban/datasets/MNBVC/</span><br><span class="line"></span><br><span class="line">export https_proxy=http://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">57901</span> http_proxy=http://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">57901</span> all_proxy=socks5://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">57901</span></span><br><span class="line"></span><br><span class="line">nohup dolma -c /tokenizer.yaml tokens &gt; /mnt/LLM-pretrain-dataset/luchenhao/logfile.log <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br><span class="line"></span><br><span class="line">split -l <span class="number">1000000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-000122-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-000122-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/WebText2_cn_split_</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/截屏2024-07-09 13.32.59.png" alt="截屏2024-07-09 13.32.59"></p>
<p>LLaMA [34] 的预训练数据主要包括超过 80% 的网页数据、 来自 GitHub 和 StackExchange 的 6.5% 代码密集型数据、4.5% 的书籍数据,以及来自 arXiv 的 2.5% 科学数据, 这个数据配比成为了训练大语言模型的一个重要参考。<br>根据这个比例,网页数据在现有预训练数据占据了较大的比重,为大语言模型提供了丰富的世界知识。此外,也可以为实现不同的目的来设计特定的数据混合配比。例如,专业的代码模型 CodeGen [94] 大幅增加了代码数据的比例。值得注意的是,即使是在这样的专业模型中,依然需要混合一定的网页数据来提供或者保留通用的语义知识。】】</p>
<h2 id="语料分类情况下进行词元化"><a href="#语料分类情况下进行词元化" class="headerlink" title="语料分类情况下进行词元化"></a>语料分类情况下进行词元化</h2><div class="table-container">
<table>
<thead>
<tr>
<th>语料</th>
<th>预期配比</th>
<th>英文中配比</th>
<th>文件数</th>
<th>tokens</th>
<th>路径</th>
</tr>
</thead>
<tbody>
<tr>
<td>中文</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>WuDao</td>
<td></td>
<td></td>
<td>7</td>
<td>2.66B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/WuDao/tokens/train</td>
</tr>
<tr>
<td>WuDaoa_all</td>
<td></td>
<td></td>
<td></td>
<td>38.21B</td>
<td></td>
</tr>
<tr>
<td>MNBVC</td>
<td></td>
<td></td>
<td></td>
<td>0.65B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/MNBVC/MNBVC/tokens</td>
</tr>
<tr>
<td>Baike</td>
<td></td>
<td></td>
<td>6</td>
<td>0.54B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/Baike/tokens</td>
</tr>
<tr>
<td>Wikipedia-cn</td>
<td></td>
<td></td>
<td>1</td>
<td>0.13B</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>CC</td>
<td>30</td>
<td>45.77%</td>
<td>31</td>
<td>31.92B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/CC/sample/tokens</td>
</tr>
<tr>
<td>C4</td>
<td>10</td>
<td>17.31%</td>
<td>12</td>
<td>9.49B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/C4/tokens/sample</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reddit</td>
<td>5</td>
<td>14.13%</td>
<td>5</td>
<td>5.14B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/reddit/tokens</td>
</tr>
<tr>
<td>RefinedWeb</td>
<td>5</td>
<td>10.7%</td>
<td>6</td>
<td>5.54B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/RefinedWeb/tokens</td>
</tr>
<tr>
<td>StackExchange</td>
<td>2.5</td>
<td>6.42%</td>
<td>4</td>
<td>2.64B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/StackExchange/tokens</td>
</tr>
<tr>
<td>books</td>
<td>2.5</td>
<td>3.72%</td>
<td>2</td>
<td>2.90B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/books/tokens</td>
</tr>
<tr>
<td>arxiv</td>
<td>2.5</td>
<td>1.95%</td>
<td>8</td>
<td>2.5B</td>
<td>/mnt/LLM-pretrain-dataset/luchenhao/arxiv/tokens</td>
</tr>
<tr>
<td>Starcoder</td>
<td>2.5</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TOTAL</td>
<td></td>
<td></td>
<td></td>
<td>136.97B</td>
</tr>
</tbody>
</table>
</div>
<h2 id="语料不分类情况下进行词元化"><a href="#语料不分类情况下进行词元化" class="headerlink" title="语料不分类情况下进行词元化"></a>语料不分类情况下进行词元化</h2><h2 id="Dolma-Pipeline"><a href="#Dolma-Pipeline" class="headerlink" title="Dolma Pipeline"></a>Dolma Pipeline</h2><ol>
<li><p>python /reformat.py</p>
</li>
<li><p>dolma -c /taggers.yaml tag</p>
</li>
<li><p>dolma -c /dedupe.yaml dedupe</p>
</li>
<li><p>dolma -c /mix.yaml mix</p>
</li>
<li><p>dolma -c /tokenizer.yaml tokens  -&gt; npy文件</p>
</li>
<li><p>/OLMo-1B.yamldata: </p>
<p> ​    paths:- /mnt/geogpt-gpfs/llmcourse/public/datasets/npy_data/RedPajamaGithub/0199_00000.npy</p>
<p> ​          - /mnt/geogpt-gpfs/llmcourse/public/datasets/npy_data/RedPajamaGithub/1087_00000.npy</p>
</li>
<li><p>CUDA_VISIBLE_DEVICES=1 torchrun —nproc_per_node=1 /OLMo/scripts/train.py configs/OLMo-1B.yaml —save-folder=olmo-run</p>
</li>
</ol>
<h2 id="数据下载-python-reformat-py"><a href="#数据下载-python-reformat-py" class="headerlink" title="数据下载 python /reformat.py"></a>数据下载 python /reformat.py</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #!/bin/bash</span></span><br><span class="line"><span class="comment"># DATA_DIR=&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line"><span class="comment"># PARALLEL_DOWNLOADS=&quot;16&quot;</span></span><br><span class="line"><span class="comment"># DOLMA_VERSION=&quot;v1_7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># git clone https://huggingface.co/datasets/allenai/dolma</span></span><br><span class="line"><span class="comment"># mkdir -p &quot;$&#123;DATA_DIR&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat &quot;dolma/urls/$&#123;DOLMA_VERSION&#125;.txt&quot; | xargs -n 1 -P &quot;$&#123;PARALLEL_DOWNLOADS&#125;&quot; wget -q -P &quot;$DATA_DIR&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置变量</span></span><br><span class="line">DATA_DIR=<span class="string">&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line">PARALLEL_DOWNLOADS=<span class="string">&quot;16&quot;</span></span><br><span class="line">DOLMA_VERSION=<span class="string">&quot;v1_7&quot;</span></span><br><span class="line">LOG_FILE=<span class="string">&quot;download_dolma.log&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 克隆 Dolma 数据集的存储库</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/allenai/dolma</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据目录，如果目录不存在的话</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$&#123;DATA_DIR&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从指定版本的 URL 文件中读取 URL 并使用 wget 断点续传并显示进度到数据目录</span></span><br><span class="line"><span class="built_in">cat</span> <span class="string">&quot;dolma/urls/<span class="variable">$&#123;DOLMA_VERSION&#125;</span>.txt&quot;</span> | xargs -n 1 -P <span class="string">&quot;<span class="variable">$&#123;PARALLEL_DOWNLOADS&#125;</span>&quot;</span> wget -c --progress=bar:force -P <span class="string">&quot;<span class="variable">$DATA_DIR</span>&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup ./download_dolma.sh &gt; script_output.log <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地文件目录</span></span><br><span class="line">local_dir=<span class="string">&quot;/mnt/nas_v2/dolma_v1_7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL 文件</span></span><br><span class="line">url_file=<span class="string">&quot;/home/luchenhao/dolma/urls/v1_7.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历 url.txt 中的每一行</span></span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r url; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 获取文件名</span></span><br><span class="line">    filename=$(<span class="built_in">basename</span> <span class="string">&quot;<span class="variable">$url</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查远程文件大小</span></span><br><span class="line">    remote_size=$(wget --spider <span class="string">&quot;<span class="variable">$url</span>&quot;</span> 2&gt;&amp;1 | grep Length | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查命令是否成功</span></span><br><span class="line">    <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Failed to check remote file: <span class="variable">$url</span>&quot;</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取本地文件大小（以字节为单位）</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        local_size=$(<span class="built_in">du</span> -b <span class="string">&quot;<span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span> | <span class="built_in">cut</span> -f1)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Local file does not exist: <span class="variable">$local_dir</span>/<span class="variable">$filename</span>&quot;</span></span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将本地文件大小和远程文件大小进行比较</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$remote_size</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$local_size</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;File sizes match for <span class="variable">$filename</span>: <span class="variable">$local_size</span> bytes&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;File size mismatch for <span class="variable">$filename</span>: local = <span class="variable">$local_size</span> bytes, remote = <span class="variable">$remote_size</span> bytes&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span> &lt; <span class="string">&quot;<span class="variable">$url_file</span>&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup ./check_file_sizes.sh &gt; script_output2.log <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<h2 id="数据转换（关键key添加、转换为Jsonl、压缩）"><a href="#数据转换（关键key添加、转换为Jsonl、压缩）" class="headerlink" title="数据转换（关键key添加、转换为Jsonl、压缩）"></a>数据转换（关键key添加、转换为Jsonl、压缩）</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ history | grep reformat</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_to_b_format</span>(<span class="params">a_sample</span>):</span><br><span class="line">    b_sample = &#123;</span><br><span class="line">        <span class="string">&quot;id&quot;</span>: <span class="built_in">str</span>(a_sample[<span class="string">&quot;id&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;text&quot;</span>: a_sample[<span class="string">&quot;content&quot;</span>],</span><br><span class="line">        <span class="string">&quot;source&quot;</span>: <span class="string">&quot;WuDaoCorpus2&quot;</span>,  <span class="comment"># 可以根据实际情况调整</span></span><br><span class="line">        <span class="string">&quot;added&quot;</span>: datetime.now().isoformat(),  <span class="comment"># 当前时间</span></span><br><span class="line">        <span class="string">&quot;created&quot;</span>: <span class="literal">None</span>,  <span class="comment"># 假设创建时间不确定，可以根据实际情况调整</span></span><br><span class="line">        <span class="string">&quot;metadata&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;uniqueKey&quot;</span>: a_sample[<span class="string">&quot;uniqueKey&quot;</span>],</span><br><span class="line">            <span class="string">&quot;titleUkey&quot;</span>: a_sample[<span class="string">&quot;titleUkey&quot;</span>],</span><br><span class="line">            <span class="string">&quot;dataType&quot;</span>: a_sample[<span class="string">&quot;dataType&quot;</span>],</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: a_sample[<span class="string">&quot;title&quot;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b_sample</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">json2Dolmaformat</span>(<span class="params">sourcePath, desFile</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(sourcePath,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(desFile, <span class="string">&#x27;wt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fn:</span><br><span class="line">        <span class="keyword">for</span> segment <span class="keyword">in</span> tqdm(data, desc=<span class="string">&quot;Processing and writing segments&quot;</span>, unit=<span class="string">&quot;segment&quot;</span>):</span><br><span class="line">            b_format_data = convert_to_b_format(segment)</span><br><span class="line">            json.dump(b_format_data, fn)</span><br><span class="line">            fn.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    sourcePath = <span class="string">&#x27;/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/part-2021009337.json&#x27;</span>  <span class="comment"># 修改为实际文件路径</span></span><br><span class="line">    desFile = <span class="string">&#x27;/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents/part-2021009337_reformat.jsonl.gz&#x27;</span>  <span class="comment"># 修改为实际输出文件路径</span></span><br><span class="line">    json2Dolmaformat(sourcePath, desFile)</span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python /reformat_all.py</span><br></pre></td></tr></table></figure>
<h2 id="Tagger"><a href="#Tagger" class="headerlink" title="Tagger"></a>Tagger</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dolma tag --documents &quot;$&#123;HOME&#125;/perplexity/v2/documents/*/*/*.gz&quot; --taggers uniseg_length_paragraphs_with_empty_v1 not_alphanum_paragraph_v1 --processes 188</span></span><br><span class="line"><span class="comment"># dolma tag --documents &quot;$&#123;HOME&#125;/perplexity/v2_small/documents/*/*/*.gz&quot; --taggers uniseg_length_paragraphs_with_empty_v1 not_alphanum_paragraph_v1 --processes 188</span></span><br><span class="line"><span class="comment"># dolma tag --documents &quot;$&#123;HOME&#125;/perplexity/v3/documents/*/*/*.gz&quot; --taggers uniseg_length_paragraphs_with_empty_v1 not_alphanum_paragraph_v1 --processes 188</span></span><br><span class="line"><span class="comment"># dolma tag --documents &quot;$&#123;HOME&#125;/perplexity/v2_small_subset/documents/*/*/*.gz&quot; --taggers uniseg_length_paragraphs_with_empty_v1 not_alphanum_paragraph_v1 --processes 188</span></span><br><span class="line"></span><br><span class="line"><span class="attr">documents:</span></span><br><span class="line">  <span class="comment"># - /mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/*.json</span></span><br><span class="line">  <span class="comment"># - /mnt/dolma_v1_7/documents/*.gz</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents/*.gz</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">taggers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">c4_v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ft_lang_id_en_doc_v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">uniseg_length_paragraphs_with_empty_v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">not_alphanum_paragraph_v1</span></span><br><span class="line">  <span class="comment"># - tokenizer_repetitions_v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">char_length_strip_ws_v1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">processes:</span> <span class="number">188</span></span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ dolma -c /tagger.yaml tag</span><br></pre></td></tr></table></figure>
<h2 id="Deduplicate"><a href="#Deduplicate" class="headerlink" title="Deduplicate"></a>Deduplicate</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">documents:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents/*.gz</span></span><br><span class="line"></span><br><span class="line"><span class="attr">dedupe:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">wanjuan</span></span><br><span class="line">  <span class="attr">documents:</span></span><br><span class="line">    <span class="attr">attribute_name:</span> <span class="string">bff_duplicates</span></span><br><span class="line">    <span class="attr">key:</span> <span class="string">$.text</span></span><br><span class="line">  <span class="attr">skip_empty:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">bloom_filter:</span></span><br><span class="line">  <span class="attr">read_only:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">estimated_doc_count:</span> <span class="number">49679</span></span><br><span class="line">  <span class="comment"># size_in_bytes: 104857600  # 100 MB; smaller causes too many FPs</span></span><br><span class="line">  <span class="attr">desired_false_positive_rate:</span> <span class="number">1e-15</span></span><br><span class="line">  <span class="attr">file:</span> <span class="string">$&#123;oc.env:HOME&#125;/perplexity/filters/paloma_documents.bin</span></span><br><span class="line"></span><br><span class="line"><span class="attr">processes:</span> <span class="number">188</span></span><br></pre></td></tr></table></figure>
<h2 id="Mixer"><a href="#Mixer" class="headerlink" title="Mixer"></a>Mixer</h2><p>在JSONPath表达式中，<code>$</code>表示根元素，<code>@</code>表示当前元素。JSONPath是一种用于从JSON文档中提取数据的查询语言，类似于XPath用于XML。这个特定的JSONPath表达式用于筛选出符合特定条件的对象。让我们逐部分分析这个表达式：</p>
<h3 id="JSONPath表达式解析"><a href="#JSONPath表达式解析" class="headerlink" title="JSONPath表达式解析"></a>JSONPath表达式解析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$@.attributes[?(@.bff_duplicates &amp;&amp; @.bff_duplicates[0] &amp;&amp; @.bff_duplicates[0][2] &gt;= 1.0)]</span><br></pre></td></tr></table></figure>
<h4 id="分段解释"><a href="#分段解释" class="headerlink" title="分段解释"></a>分段解释</h4><ol>
<li><p><strong><code>$</code></strong>:</p>
<ul>
<li>根元素。表示整个JSON文档的起点。</li>
</ul>
</li>
<li><p><strong><code>@</code></strong>:</p>
<ul>
<li>当前元素。在过滤表达式中，<code>@</code>表示当前处理的对象。</li>
</ul>
</li>
<li><p><strong><code>.attributes</code></strong>:</p>
<ul>
<li>访问当前元素的<code>attributes</code>字段。假设每个对象都有一个<code>attributes</code>字段。</li>
</ul>
</li>
<li><p><strong><code>[?()]</code></strong>:</p>
<ul>
<li>过滤操作。里面的内容定义了过滤条件。</li>
</ul>
</li>
<li><p><strong><code>@.bff_duplicates</code></strong>:</p>
<ul>
<li>访问<code>attributes</code>对象的<code>bff_duplicates</code>字段。</li>
</ul>
</li>
<li><p><strong><code>@.bff_duplicates[0]</code></strong>:</p>
<ul>
<li>访问<code>bff_duplicates</code>数组的第一个元素。</li>
</ul>
</li>
<li><p><strong><code>@.bff_duplicates[0][2] &gt;= 1.0</code></strong>:</p>
<ul>
<li>检查<code>bff_duplicates</code>数组第一个元素的第三个值是否大于或等于1.0。</li>
</ul>
</li>
</ol>
<h4 id="综合解释"><a href="#综合解释" class="headerlink" title="综合解释"></a>综合解释</h4><p>这个JSONPath表达式的整体意思是：</p>
<ul>
<li>选择<code>attributes</code>字段中的对象。</li>
<li>检查<code>bff_duplicates</code>字段是否存在且不为空。</li>
<li>检查<code>bff_duplicates</code>数组中的第一个元素是否存在且不为空。</li>
<li>检查<code>bff_duplicates</code>数组第一个元素的第三个值是否大于或等于1.0。</li>
</ul>
<p>如果所有这些条件都满足，则这个<code>attributes</code>对象被选中。</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>假设你有如下JSON文档：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;attributes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;bff_duplicates&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">1.2</span><span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>在这个示例中：</p>
<ul>
<li><code>bff_duplicates</code>存在。</li>
<li><code>bff_duplicates</code>数组的第一个元素存在。</li>
<li>第一个元素的第三个值是<code>1.2</code>，满足大于或等于<code>1.0</code>的条件。</li>
</ul>
<p>因此，这个对象会被选中。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;attributes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;bff_duplicates&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">1.2</span><span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>如果<code>bff_duplicates</code>数组为空或者其第一个元素的第三个值小于<code>1.0</code>，则这个对象不会被选中。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个JSONPath表达式用于在JSON文档中筛选出包含特定条件的<code>attributes</code>对象，特别是那些<code>bff_duplicates</code>数组的第一个元素的第三个值大于或等于<code>1.0</code>的对象。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mix command operates on one or more stream; each can correspond to a different data source</span></span><br><span class="line"><span class="comment"># and can have its own set of filters and transformations</span></span><br><span class="line"><span class="attr">streams:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">getting-started</span> <span class="comment"># name of the stream; this will be used as a prefix for the output files</span></span><br><span class="line">      <span class="attr">documents:</span> <span class="comment"># the documents to mix; note how we use a glob pattern to match all documents</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents/*.gz</span></span><br><span class="line">      <span class="comment"># this is the directory where the output will be written</span></span><br><span class="line">      <span class="comment"># note how the toolkit will try to create files of size ~1GB</span></span><br><span class="line">      <span class="attr">output:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents</span> <span class="comment">#输出路径，指定了输出文件的位置。</span></span><br><span class="line">        <span class="attr">max_size_in_bytes:</span> <span class="string">1_000_000_000</span> <span class="comment">#单个输出文件的最大大小，单位为字节。这里设置为 1,000,000,000 字节（即 1 GB）</span></span><br><span class="line">      <span class="attr">attributes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">ft_lang_id_en_doc_v2</span> <span class="comment"># load the attributes from the taggers</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">wanjuan</span> <span class="comment"># load the attributes from the deduper</span></span><br><span class="line">      <span class="attr">filter:</span></span><br><span class="line">        <span class="attr">include:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;$.attributes[?(@.ft_lang_id_en_doc_v2__ft_lang_id_en_doc_v2__not_en[0][2] &lt; 0.99)]&quot;</span></span><br><span class="line">          <span class="comment">#  JSONPath 表达式, 从 JSON 数据结构中筛选出具有 paloma_documents_bff_duplicates 属性的 attributes 数组元素，并且该属性的第一个元素的第三个值（索引为 2）大于或等于 1.0。</span></span><br><span class="line">        <span class="attr">exclude:</span></span><br><span class="line">          <span class="comment"># - &quot;$.attributes[?(@.exp__whitespace_tokenizer_with_paragraphs_v1__document[0][2] &lt; 50)]&quot;</span></span><br><span class="line">          <span class="comment"># - &quot;$.attributes[?(@.exp__ft_lang_id_en_paragraph_with_doc_score_v2__doc_en[0][2] &lt;= 0.5)]&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;$@.attributes[?(@.bff_duplicates &amp;&amp; @.bff_duplicates[0] &amp;&amp; @.bff_duplicates[0][2] &gt;= 1.0)]&quot;</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># span_replacement:</span></span><br><span class="line">      <span class="comment">#   - span: &quot;$.attributes.exp__cld2_en_paragraph_with_doc_score_v2__not_en&quot;</span></span><br><span class="line">      <span class="comment">#     min_score: 0.1 #这是一个分数阈值，只有当 span 的分数大于等于这个值时，才会进行替换。</span></span><br><span class="line">      <span class="comment">#     replacement: &#x27;&#x27; #替换成空字符串</span></span><br><span class="line"></span><br><span class="line"><span class="attr">processes:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">destination:</span> <span class="string">/mnt/LLM-pretrain-dataset/luchenhao/C4/tokens</span></span><br><span class="line"><span class="attr">documents:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/mnt/LLM-pretrain-dataset/luchenhao/C4/*.json.gz</span></span><br><span class="line"><span class="attr">processes:</span> <span class="number">188</span></span><br><span class="line"><span class="attr">seed:</span> <span class="number">3920</span></span><br><span class="line"><span class="attr">max_size:</span> <span class="string">21_474_836_480</span></span><br><span class="line"><span class="attr">dtype:</span> <span class="string">uint32</span></span><br><span class="line"></span><br><span class="line"><span class="attr">tokenizer:</span></span><br><span class="line">  <span class="attr">name_or_path:</span> <span class="string">Qwen/Qwen2-7B-Instruct</span></span><br><span class="line">  <span class="attr">bos_token_id:</span> <span class="number">151644</span></span><br><span class="line">  <span class="attr">eos_token_id:</span> <span class="number">151645</span></span><br><span class="line">  <span class="attr">pad_token_id:</span> <span class="number">151643</span></span><br><span class="line">  <span class="attr">segment_before_tokenization:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup dolma -c /tokenizer.yaml tokens &gt; /mnt/LLM-pretrain-dataset/luchenhao/logfile.log <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<h2 id="分词器解码校验"><a href="#分词器解码校验" class="headerlink" title="分词器解码校验"></a>分词器解码校验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">local_tokenizer_path = <span class="string">&quot;/llm-practice/OLMo-0.3.0/tokenizers/tokenizer.json&quot;</span></span><br><span class="line"><span class="comment"># data = np.load(&quot;/mnt/LLM-pretrain-dataset/WuDaoCorpus2.0/WuDaoCorpus2.0_base_200G/WuDaoCorpus2.0_base_200G/documents/part-0-00000.npy&quot;, allow_pickle=True)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_tokenize</span>():</span><br><span class="line">    <span class="comment"># tokenizer = AutoTokenizer.from_pretrained(&quot;/llm-practice/OLMo-0.3.0/tokenizers&quot;)</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;Qwen/Qwen2-7B-Instruct&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;/mnt/LLM-pretrain-dataset/luchenhao/C4/tokens/part-001-00000.npy&quot;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = np.fromfile(f, dtype=np.uint32)</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        <span class="built_in">print</span>(data.size)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;The file contains <span class="subst">&#123;data.size / <span class="number">1e9</span>:<span class="number">.2</span>f&#125;</span> billion tokens.&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(tokenizer.decode(data[:<span class="number">10000</span>]))</span><br><span class="line">check_tokenize()</span><br></pre></td></tr></table></figure>
<h2 id="tar文件解压"><a href="#tar文件解压" class="headerlink" title="tar文件解压"></a>tar文件解压</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xvzf /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/Exam-cn/part-<span class="number">003756</span>-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/Exam-cn/part-<span class="number">003756</span>-a894b46e.jsonl.tar.gz</span><br></pre></td></tr></table></figure>
<h2 id="tar文件切分"><a href="#tar文件切分" class="headerlink" title="tar文件切分"></a>tar文件切分</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ split -l <span class="number">500000</span> --additional-suffix=.jsonl /mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-<span class="number">000036</span>-a894b46e.jsonl.tar.gz/OpenDataLab___WanJuan1_dot_0/raw/nlp/CN/WebText-cn/part-<span class="number">000036</span>-a894b46e.jsonl /mnt/LLM-pretrain-dataset/luchenhao/WanJuan/documents/WebText1_cn_split_</span><br></pre></td></tr></table></figure>
<h2 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_lines_in_file</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> _ <span class="keyword">in</span> f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_lines_from_file</span>(<span class="params">input_path, output_path, fraction=<span class="number">0.1</span>, seed=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        random.seed(seed)</span><br><span class="line"></span><br><span class="line">    total_lines = count_lines_in_file(input_path)</span><br><span class="line">    sample_size = <span class="built_in">int</span>(total_lines * fraction)</span><br><span class="line">    </span><br><span class="line">    sampled_lines = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(input_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_in:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f_in, total=total_lines, desc=<span class="string">&quot;Reading lines&quot;</span>):</span><br><span class="line">            <span class="keyword">if</span> random.random() &lt; fraction:</span><br><span class="line">                sampled_lines.append(line)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(sampled_lines) &gt;= sample_size:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&#x27;wt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_out:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(sampled_lines, total=sample_size, desc=<span class="string">&quot;Writing lines&quot;</span>):</span><br><span class="line">            f_out.write(line)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入和输出文件路径</span></span><br><span class="line">input_file = <span class="string">&#x27;/1GB_ad.jsonl&#x27;</span></span><br><span class="line">output_file = <span class="string">&#x27;/mnt/LLM-pretrain-dataset/WanJuan1_dot_0/raw/nlp/CN/ChinaNews-cn/1GB_ad.jsonl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按比例采样并保存为新的 .jsonl.gz 文件</span></span><br><span class="line">sample_lines_from_file(input_file, output_file, fraction=<span class="number">0.05</span>, seed=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h2 id="token量计算"><a href="#token量计算" class="headerlink" title="token量计算"></a>token量计算</h2><p>一个 <code>.npy</code> 文件的大小与其包含的 token 数量之间的关系取决于每个 token 所占的存储空间。为了估算 <code>568.00 MB</code> 的 <code>.npy</code> 文件中包含 <code>0.15B</code>（即 <code>150,000,000</code>）个 tokens，首先需要了解每个 token 的字节大小。</p>
<p>假设 <code>.npy</code> 文件中存储的是一个整数数组，每个 token 对应一个整数，通常使用 <code>int32</code> 或 <code>int64</code> 类型来存储。</p>
<h3 id="估算过程"><a href="#估算过程" class="headerlink" title="估算过程"></a>估算过程</h3><ol>
<li><p><strong>计算每个 token 的字节大小</strong>：</p>
<ul>
<li><code>int32</code> 类型：每个整数占用 4 字节</li>
<li><code>int64</code> 类型：每个整数占用 8 字节</li>
</ul>
</li>
<li><p><strong>计算总 token 数量</strong>：</p>
<ul>
<li>假设 <code>.npy</code> 文件中每个 token 占用 <code>int32</code> 类型（4 字节）</li>
<li>文件大小为 <code>568.00 MB</code>，即 <code>568 * 1024 * 1024 = 595591168</code> 字节</li>
</ul>
<p>计算 token 数量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_tokens = total_bytes / bytes_per_token</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>实际计算</strong>：</p>
<ul>
<li>使用 <code>int32</code> 类型时，每个 token 占用 4 字节：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_tokens = <span class="number">595591168</span> / <span class="number">4</span></span><br></pre></td></tr></table></figure></li>
<li>使用 <code>int64</code> 类型时，每个 token 占用 8 字节：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_tokens = <span class="number">595591168</span> / <span class="number">8</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h3 id="计算示例"><a href="#计算示例" class="headerlink" title="计算示例"></a>计算示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">total_bytes = <span class="number">568</span> * <span class="number">1024</span> * <span class="number">1024</span>  <span class="comment"># 568 MB in bytes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For int32</span></span><br><span class="line">bytes_per_token_int32 = <span class="number">4</span></span><br><span class="line">total_tokens_int32 = total_bytes / bytes_per_token_int32</span><br><span class="line"></span><br><span class="line"><span class="comment"># For int64</span></span><br><span class="line">bytes_per_token_int64 = <span class="number">8</span></span><br><span class="line">total_tokens_int64 = total_bytes / bytes_per_token_int64</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total tokens (int32): <span class="subst">&#123;total_tokens_int32:<span class="number">.2</span>e&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total tokens (int64): <span class="subst">&#123;total_tokens_int64:<span class="number">.2</span>e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>假设使用 <code>int32</code> 类型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">total_bytes = <span class="number">568</span> * <span class="number">1024</span> * <span class="number">1024</span>  <span class="comment"># 568 MB in bytes</span></span><br><span class="line">bytes_per_token_int32 = <span class="number">4</span></span><br><span class="line">total_tokens_int32 = total_bytes / bytes_per_token_int32</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total tokens (int32): <span class="subst">&#123;total_tokens_int32:<span class="number">.2</span>e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Total tokens (int32): <span class="number">1.49e+08</span></span><br></pre></td></tr></table></figure></p>
<p>即大约 <code>149,000,000</code> 个 tokens，与 <code>0.15B</code> tokens 非常接近。</p>
<p>假设使用 <code>int64</code> 类型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">total_bytes = <span class="number">568</span> * <span class="number">1024</span> * <span class="number">1024</span>  <span class="comment"># 568 MB in bytes</span></span><br><span class="line">bytes_per_token_int64 = <span class="number">8</span></span><br><span class="line">total_tokens_int64 = total_bytes / bytes_per_token_int64</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total tokens (int64): <span class="subst">&#123;total_tokens_int64:<span class="number">.2</span>e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Total tokens (int64): <span class="number">7.45e+07</span></span><br></pre></td></tr></table></figure></p>
<p>即大约 <code>74,500,000</code> 个 tokens，少于 <code>0.15B</code> tokens。</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>对于一个 <code>568.00 MB</code> 的 <code>.npy</code> 文件，如果每个 token 占用 <code>int32</code>（4 字节），那么大约包含 <code>0.15B</code>（150,000,000）个 tokens。这与估算的结果一致。因此，可以合理地推测 <code>.npy</code> 文件中每个 token 占用 <code>4</code> 字节。</p>
<h2 id="token量和npy文件大小的转换"><a href="#token量和npy文件大小的转换" class="headerlink" title="token量和npy文件大小的转换"></a>token量和npy文件大小的转换</h2><p>要计算存储 100B 个 tokens 需要多大的 <code>.npy</code> 文件，我们需要了解每个 token 的字节大小。通常，tokens 是以整数形式存储的，可以是 <code>int32</code> 或 <code>int64</code> 类型。我们将分别计算使用 <code>int32</code> 和 <code>int64</code> 类型存储 tokens 所需的文件大小。</p>
<h3 id="使用-int32-类型存储-tokens"><a href="#使用-int32-类型存储-tokens" class="headerlink" title="使用 int32 类型存储 tokens"></a>使用 <code>int32</code> 类型存储 tokens</h3><p>每个 <code>int32</code> 整数占用 4 字节。</p>
<h4 id="计算公式："><a href="#计算公式：" class="headerlink" title="计算公式："></a>计算公式：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file_size_int32 = number_of_tokens * bytes_per_token</span><br></pre></td></tr></table></figure>
<h4 id="实际计算："><a href="#实际计算：" class="headerlink" title="实际计算："></a>实际计算：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">number_of_tokens = <span class="number">100</span> * <span class="number">10</span>**<span class="number">9</span>  <span class="comment"># 100 billion tokens</span></span><br><span class="line">bytes_per_token_int32 = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">file_size_int32 = number_of_tokens * bytes_per_token_int32  <span class="comment"># in bytes</span></span><br><span class="line">file_size_int32_gb = file_size_int32 / (<span class="number">1024</span> ** <span class="number">3</span>)  <span class="comment"># convert to GB</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File size for 100B tokens (int32): <span class="subst">&#123;file_size_int32_gb:<span class="number">.2</span>f&#125;</span> GB&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="使用-int64-类型存储-tokens"><a href="#使用-int64-类型存储-tokens" class="headerlink" title="使用 int64 类型存储 tokens"></a>使用 <code>int64</code> 类型存储 tokens</h3><p>每个 <code>int64</code> 整数占用 8 字节。</p>
<h4 id="计算公式：-1"><a href="#计算公式：-1" class="headerlink" title="计算公式："></a>计算公式：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file_size_int64 = number_of_tokens * bytes_per_token</span><br></pre></td></tr></table></figure>
<h4 id="实际计算：-1"><a href="#实际计算：-1" class="headerlink" title="实际计算："></a>实际计算：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">number_of_tokens = <span class="number">100</span> * <span class="number">10</span>**<span class="number">9</span>  <span class="comment"># 100 billion tokens</span></span><br><span class="line">bytes_per_token_int64 = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">file_size_int64 = number_of_tokens * bytes_per_token_int64  <span class="comment"># in bytes</span></span><br><span class="line">file_size_int64_gb = file_size_int64 / (<span class="number">1024</span> ** <span class="number">3</span>)  <span class="comment"># convert to GB</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File size for 100B tokens (int64): <span class="subst">&#123;file_size_int64_gb:<span class="number">.2</span>f&#125;</span> GB&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="完整代码示例"><a href="#完整代码示例" class="headerlink" title="完整代码示例"></a>完整代码示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the number of tokens and bytes per token for int32 and int64</span></span><br><span class="line">number_of_tokens = <span class="number">100</span> * <span class="number">10</span>**<span class="number">9</span>  <span class="comment"># 100 billion tokens</span></span><br><span class="line">bytes_per_token_int32 = <span class="number">4</span></span><br><span class="line">bytes_per_token_int64 = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate file size for int32</span></span><br><span class="line">file_size_int32 = number_of_tokens * bytes_per_token_int32  <span class="comment"># in bytes</span></span><br><span class="line">file_size_int32_gb = file_size_int32 / (<span class="number">1024</span> ** <span class="number">3</span>)  <span class="comment"># convert to GB</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate file size for int64</span></span><br><span class="line">file_size_int64 = number_of_tokens * bytes_per_token_int64  <span class="comment"># in bytes</span></span><br><span class="line">file_size_int64_gb = file_size_int64 / (<span class="number">1024</span> ** <span class="number">3</span>)  <span class="comment"># convert to GB</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File size for 100B tokens (int32): <span class="subst">&#123;file_size_int32_gb:<span class="number">.2</span>f&#125;</span> GB&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File size for 100B tokens (int64): <span class="subst">&#123;file_size_int64_gb:<span class="number">.2</span>f&#125;</span> GB&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h3><p>运行上述代码后，你会得到以下输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File size <span class="keyword">for</span> 100B tokens (int32): <span class="number">372.53</span> GB</span><br><span class="line">File size <span class="keyword">for</span> 100B tokens (int64): <span class="number">745.06</span> GB</span><br></pre></td></tr></table></figure>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><ul>
<li>如果使用 <code>int32</code> 类型（每个 token 占用 4 字节），存储 100B 个 tokens 需要大约 372.53 GB 的 <code>.npy</code> 文件。</li>
<li>如果使用 <code>int64</code> 类型（每个 token 占用 8 字节），存储 100B 个 tokens 需要大约 745.06 GB 的 <code>.npy</code> 文件。</li>
</ul>
<p>根据实际需求选择合适的数据类型和存储空间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv /mnt/LLM-pretrain-dataset/WuDaoCorpus2<span class="number">.0</span>/WuDaoCorpus2<span class="number">.0</span>_base_200G/WuDaoCorpus2<span class="number">.0</span>_base_200G/documents/*_dolma.jsonl.gz /mnt/LLM-pretrain-dataset/luchenhao/WuDao/documents</span><br><span class="line"></span><br><span class="line">ls /mnt/LLM-pretrain-dataset/luchenhao/CC | shuf -n <span class="number">60</span> | xargs -I &#123;&#125; mv /mnt/LLM-pretrain-dataset/luchenhao/CC/&#123;&#125; /mnt/LLM-pretrain-dataset/luchenhao/CC/sample/</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=4,5,6,7 torchrun --nproc_per_node=4 /OLMo/scripts/train.py /OLMo/configs/official/OLMo-1B.yaml --save-folder=olmo-run-test-v4 --save_overwrite</span><br></pre></td></tr></table></figure>
<p>在分布式训练中，有多种并行策略来提高训练效率和处理更大规模的模型。主要的策略包括数据并行 (DP)、模型并行 (MP)、流水线并行 (PP) 和完全分片数据并行 (FSDP)。以下是这些策略的详细解释及其关系：</p>
<h3 id="数据并行-Data-Parallel-DP"><a href="#数据并行-Data-Parallel-DP" class="headerlink" title="数据并行 (Data Parallel, DP)"></a>数据并行 (Data Parallel, DP)</h3><p><strong>概念</strong>：</p>
<ul>
<li>在数据并行中，每个设备（如 GPU）都拥有整个模型的一个副本。每个设备处理不同的 mini-batch 数据。</li>
<li>在每个设备上独立计算梯度，然后聚合所有设备上的梯度，更新所有模型副本的参数。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>实现简单，扩展性好。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>每个设备需要存储整个模型，因此对于非常大的模型，单个设备的内存可能不足。</li>
</ul>
<p><strong>示例</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">10</span>).to(rank)</span><br><span class="line">ddp_model = DDP(model, device_ids=[rank])</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="模型并行-Model-Parallel-MP"><a href="#模型并行-Model-Parallel-MP" class="headerlink" title="模型并行 (Model Parallel, MP)"></a>模型并行 (Model Parallel, MP)</h3><p><strong>概念</strong>：</p>
<ul>
<li>在模型并行中，模型被分割成多个部分，每个部分在不同的设备上运行。</li>
<li>适用于单个设备内存不足以容纳整个模型的情况。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>可以处理非常大的模型。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>通信开销大，编程复杂。</li>
</ul>
<p><strong>示例</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ModelPart1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 一部分模型在设备0上</span></span><br><span class="line">        <span class="keyword">return</span> x.to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ModelPart2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 另一部分模型在设备1上</span></span><br><span class="line">        <span class="keyword">return</span> x.to(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model_part1 = ModelPart1().to(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model_part2 = ModelPart2().to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="流水线并行-Pipeline-Parallel-PP"><a href="#流水线并行-Pipeline-Parallel-PP" class="headerlink" title="流水线并行 (Pipeline Parallel, PP)"></a>流水线并行 (Pipeline Parallel, PP)</h3><p><strong>概念</strong>：</p>
<ul>
<li>将模型分成多个阶段，每个阶段在不同的设备上运行，类似于流水线作业。</li>
<li>每个阶段处理一个 mini-batch 的不同部分。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>可以处理非常大的模型，且相对高效。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>需要复杂的同步机制，编程复杂。</li>
</ul>
<p><strong>示例</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.distributed.pipeline.sync <span class="keyword">import</span> Pipe</span><br><span class="line"></span><br><span class="line">model = nn.Sequential(part1, part2)</span><br><span class="line">model = Pipe(model, chunks=<span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="完全分片数据并行-Fully-Sharded-Data-Parallel-FSDP"><a href="#完全分片数据并行-Fully-Sharded-Data-Parallel-FSDP" class="headerlink" title="完全分片数据并行 (Fully Sharded Data Parallel, FSDP)"></a>完全分片数据并行 (Fully Sharded Data Parallel, FSDP)</h3><p><strong>概念</strong>：</p>
<ul>
<li>FSDP 是一种结合了数据并行和模型并行的策略，将模型参数和优化器状态完全分片到多个设备上。</li>
<li>训练时，每个设备只保存一部分参数和优化器状态，前向和后向传播时才聚合这些参数。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>高效利用内存，可以处理更大的模型。</li>
<li>自动管理参数和优化器状态的分片和聚合。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>实现复杂，需要合适的库支持（如 PyTorch 的 <code>torch.distributed.fsdp</code>）。</li>
</ul>
<p><strong>示例</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributed.fsdp <span class="keyword">as</span> fsdp</span><br><span class="line"></span><br><span class="line">model = fsdp.FullyShardedDataParallel(model)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="总结及关系"><a href="#总结及关系" class="headerlink" title="总结及关系"></a>总结及关系</h3><ul>
<li><strong>DP</strong>：适用于可以在单个设备上存储整个模型，但需要处理大量数据的情况。</li>
<li><strong>MP</strong>：适用于单个设备无法容纳整个模型的情况，将模型切分到多个设备上。</li>
<li><strong>PP</strong>：类似于模型并行，但将模型切分为多个阶段，每个阶段处理一个 mini-batch 的不同部分。</li>
<li><strong>FSDP</strong>：结合了数据并行和模型并行的优点，能够高效地利用内存和计算资源来处理超大规模的模型。</li>
</ul>
<p>这些并行策略可以根据具体的需求和硬件资源进行选择和组合使用，以提高训练效率和模型规模。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">@dataclass</span><br><span class="line">class TrainConfig(BaseConfig):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    OLMo training configuration.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    run_name: Optional[str] = None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    The name of the run.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    seed: int = 6198</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Used to seed all initial RNG states.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    epoch: Optional[int] = None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Increment this when starting a new epoch.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @property</span><br><span class="line">    def autocast_precision(self) -&gt; torch.dtype:</span><br><span class="line">        if self.precision == &quot;amp_bf16&quot;:</span><br><span class="line">            return torch.bfloat16</span><br><span class="line">        elif self.precision == &quot;amp_fp16&quot;:</span><br><span class="line">            return torch.float16</span><br><span class="line">        elif self.precision == &quot;fp32&quot;:</span><br><span class="line">            return torch.float32</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(f&quot;Unexpected precision type &#x27;&#123;self.precision&#125;&#x27;&quot;)</span><br><span class="line"></span><br><span class="line">    @property</span><br><span class="line">    def fsdp_precision(self) -&gt; MixedPrecision:</span><br><span class="line">        if self.fsdp is not None:</span><br><span class="line">            if self.fsdp.precision == FSDPPrecision.pure:</span><br><span class="line">                return MixedPrecision(</span><br><span class="line">                    param_dtype=self.autocast_precision,</span><br><span class="line">                    reduce_dtype=self.autocast_precision,</span><br><span class="line">                    buffer_dtype=self.autocast_precision,</span><br><span class="line">                )</span><br><span class="line">            elif self.fsdp.precision == FSDPPrecision.mixed:</span><br><span class="line">                return MixedPrecision(</span><br><span class="line">                    param_dtype=self.autocast_precision,</span><br><span class="line">                    reduce_dtype=torch.float32,</span><br><span class="line">                    buffer_dtype=self.autocast_precision,</span><br><span class="line">                )</span><br><span class="line">            else:</span><br><span class="line">                raise NotImplementedError(f&quot;&#123;self.fsdp.precision&#125;&quot;)</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(&quot;self.fsdp is None!&quot;)</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def update_legacy_settings(cls, config: D) -&gt; D:</span><br><span class="line">        new_config = config.copy()</span><br><span class="line">        if om.is_dict(new_config):</span><br><span class="line">            assert isinstance(new_config, DictConfig)</span><br><span class="line"></span><br><span class="line">            if hasattr(new_config, &quot;activation_checkpointing&quot;):</span><br><span class="line">                if new_config.activation_checkpointing is False:</span><br><span class="line">                    new_config.activation_checkpointing = None</span><br><span class="line">                if new_config.activation_checkpointing is True:</span><br><span class="line">                    new_config.activation_checkpointing = ActivationCheckpointingStrategy.whole_layer</span><br><span class="line"></span><br><span class="line">            if hasattr(new_config, &quot;optimizer&quot;):</span><br><span class="line">                new_config.optimizer = OptimizerConfig.update_legacy_settings(new_config.optimizer)</span><br><span class="line"></span><br><span class="line">        return new_config</span><br></pre></td></tr></table></figure>
<h2 id="SFT"><a href="#SFT" class="headerlink" title="SFT"></a>SFT</h2><p>物理机可以用deepspeed，容器很难用deepspeed</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TMPDIR=/home/luchenhao/tmp pip install -e &quot;.[all]&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"> 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 26500/26655 [4:52:05&lt;01:18,  1.97it/s[INFO|trainer.py:3478] 2024-07-16 11:49:24,113 &gt;&gt; Saving model checkpoint to /data1/luchenhao/full/sft/checkpoint-26500                                                                                                                                                                        </span><br><span class="line">[INFO|configuration_utils.py:472] 2024-07-16 11:49:24,114 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/checkpoint-26500/config.json</span><br><span class="line">[INFO|configuration_utils.py:769] 2024-07-16 11:49:24,115 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/checkpoint-26500/generation_config.json</span><br><span class="line">[INFO|modeling_utils.py:2698] 2024-07-16 11:49:32,468 &gt;&gt; The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /data1/luchenhao/full/sft/checkpoint-26500/model.safetensors.index.json.</span><br><span class="line">[INFO|tokenization_utils_base.py:2574] 2024-07-16 11:49:32,469 &gt;&gt; tokenizer config file saved in /data1/luchenhao/full/sft/checkpoint-26500/tokenizer_config.json</span><br><span class="line">[INFO|tokenization_utils_base.py:2583] 2024-07-16 11:49:32,469 &gt;&gt; Special tokens file saved in /data1/luchenhao/full/sft/checkpoint-26500/special_tokens_map.json</span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1281, &#x27;grad_norm&#x27;: 5.426765441894531, &#x27;learning_rate&#x27;: 4.5072165447301864e-10, &#x27;epoch&#x27;: 2.98, &#x27;num_input_tokens_seen&#x27;: 123258640&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1119, &#x27;grad_norm&#x27;: 3.4162933826446533, &#x27;learning_rate&#x27;: 3.9069845541889196e-10, &#x27;epoch&#x27;: 2.98, &#x27;num_input_tokens_seen&#x27;: 123307016&#125;                                                                                                                                                 </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0351, &#x27;grad_norm&#x27;: 5.188170909881592, &#x27;learning_rate&#x27;: 3.349621975623496e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123351704&#125;                                                                                                                                                   </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0771, &#x27;grad_norm&#x27;: 5.914969444274902, &#x27;learning_rate&#x27;: 2.8351297649387154e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123400920&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0588, &#x27;grad_norm&#x27;: 5.686376094818115, &#x27;learning_rate&#x27;: 2.363508804514858e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123442360&#125;                                                                                                                                                   </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1131, &#x27;grad_norm&#x27;: 4.420042514801025, &#x27;learning_rate&#x27;: 1.9347599031965814e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123496496&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0396, &#x27;grad_norm&#x27;: 5.733197212219238, &#x27;learning_rate&#x27;: 1.5488837963123504e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123540568&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0212, &#x27;grad_norm&#x27;: 4.386143207550049, &#x27;learning_rate&#x27;: 1.205881145655008e-10, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123588848&#125;                                                                                                                                                   </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0803, &#x27;grad_norm&#x27;: 4.8516411781311035, &#x27;learning_rate&#x27;: 9.057525394873257e-11, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123633792&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1515, &#x27;grad_norm&#x27;: 4.2364044189453125, &#x27;learning_rate&#x27;: 6.484984925475557e-11, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123678416&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.0729, &#x27;grad_norm&#x27;: 5.19443416595459, &#x27;learning_rate&#x27;: 4.341194460355525e-11, &#x27;epoch&#x27;: 2.99, &#x27;num_input_tokens_seen&#x27;: 123728800&#125;                                                                                                                                                    </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1528, &#x27;grad_norm&#x27;: 5.180673122406006, &#x27;learning_rate&#x27;: 2.6261576762109943e-11, &#x27;epoch&#x27;: 3.0, &#x27;num_input_tokens_seen&#x27;: 123777840&#125;                                                                                                                                                   </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1465, &#x27;grad_norm&#x27;: 4.9111151695251465, &#x27;learning_rate&#x27;: 1.3398775143835807e-11, &#x27;epoch&#x27;: 3.0, &#x27;num_input_tokens_seen&#x27;: 123826624&#125;                                                                                                                                                  </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1316, &#x27;grad_norm&#x27;: 4.621127128601074, &#x27;learning_rate&#x27;: 4.8235618094194525e-12, &#x27;epoch&#x27;: 3.0, &#x27;num_input_tokens_seen&#x27;: 123876224&#125;                                                                                                                                                   </span><br><span class="line">&#123;&#x27;loss&#x27;: 1.1654, &#x27;grad_norm&#x27;: 5.439855098724365, &#x27;learning_rate&#x27;: 5.359514654301734e-13, &#x27;epoch&#x27;: 3.0, &#x27;num_input_tokens_seen&#x27;: 123915040&#125;                                                                                                                                                    </span><br><span class="line">100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26655/26655 [4:53:48&lt;00:00,  1.87it/s][INFO|trainer.py:3478] 2024-07-16 11:51:07,029 &gt;&gt; Saving model checkpoint to /data1/luchenhao/full/sft/checkpoint-26655</span><br><span class="line">[INFO|configuration_utils.py:472] 2024-07-16 11:51:07,030 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/checkpoint-26655/config.json</span><br><span class="line">[INFO|configuration_utils.py:769] 2024-07-16 11:51:07,031 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/checkpoint-26655/generation_config.json</span><br><span class="line">[INFO|modeling_utils.py:2698] 2024-07-16 11:51:15,234 &gt;&gt; The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /data1/luchenhao/full/sft/checkpoint-26655/model.safetensors.index.json.</span><br><span class="line">[INFO|tokenization_utils_base.py:2574] 2024-07-16 11:51:15,234 &gt;&gt; tokenizer config file saved in /data1/luchenhao/full/sft/checkpoint-26655/tokenizer_config.json</span><br><span class="line">[INFO|tokenization_utils_base.py:2583] 2024-07-16 11:51:15,235 &gt;&gt; Special tokens file saved in /data1/luchenhao/full/sft/checkpoint-26655/special_tokens_map.json</span><br><span class="line">[INFO|trainer.py:2383] 2024-07-16 11:51:28,566 &gt;&gt; </span><br><span class="line"></span><br><span class="line">Training completed. Do not forget to share your model on huggingface.co/models =)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#x27;train_runtime&#x27;: 17650.2314, &#x27;train_samples_per_second&#x27;: 36.245, &#x27;train_steps_per_second&#x27;: 1.51, &#x27;train_loss&#x27;: 1.4209418270874596, &#x27;epoch&#x27;: 3.0, &#x27;num_input_tokens_seen&#x27;: 123942712&#125;                                                                                                         </span><br><span class="line">100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26655/26655 [4:54:10&lt;00:00,  1.51it/s]</span><br><span class="line">[INFO|trainer.py:3478] 2024-07-16 11:51:28,572 &gt;&gt; Saving model checkpoint to /data1/luchenhao/full/sft</span><br><span class="line">[INFO|configuration_utils.py:472] 2024-07-16 11:51:28,573 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/config.json</span><br><span class="line">[INFO|configuration_utils.py:769] 2024-07-16 11:51:28,574 &gt;&gt; Configuration saved in /data1/luchenhao/full/sft/generation_config.json</span><br><span class="line">[INFO|modeling_utils.py:2698] 2024-07-16 11:51:36,766 &gt;&gt; The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /data1/luchenhao/full/sft/model.safetensors.index.json.</span><br><span class="line">[INFO|tokenization_utils_base.py:2574] 2024-07-16 11:51:36,767 &gt;&gt; tokenizer config file saved in /data1/luchenhao/full/sft/tokenizer_config.json</span><br><span class="line">[INFO|tokenization_utils_base.py:2583] 2024-07-16 11:51:36,767 &gt;&gt; Special tokens file saved in /data1/luchenhao/full/sft/special_tokens_map.json</span><br><span class="line">***** train metrics *****</span><br><span class="line">  epoch                    =      2.9998</span><br><span class="line">  num_input_tokens_seen    =   123942712</span><br><span class="line">  total_flos               = 743656272GF</span><br><span class="line">  train_loss               =      1.4209</span><br><span class="line">  train_runtime            =  4:54:10.23</span><br><span class="line">  train_samples_per_second =      36.245</span><br><span class="line">  train_steps_per_second   =        1.51</span><br><span class="line">Figure saved at: /data1/luchenhao/full/sft/training_loss.png</span><br><span class="line">Figure saved at: /data1/luchenhao/full/sft/training_eval_loss.png</span><br><span class="line">Figure saved at: /data1/luchenhao/full/sft/training_eval_accuracy.png</span><br><span class="line">[INFO|trainer.py:3788] 2024-07-16 11:51:37,252 &gt;&gt; </span><br><span class="line">***** Running Evaluation *****</span><br><span class="line">[INFO|trainer.py:3790] 2024-07-16 11:51:37,252 &gt;&gt;   Num examples = 11224</span><br><span class="line">[INFO|trainer.py:3793] 2024-07-16 11:51:37,252 &gt;&gt;   Batch size = 1</span><br><span class="line">100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1871/1871 [00:49&lt;00:00, 37.81it/s]</span><br><span class="line">***** eval metrics *****</span><br><span class="line">  epoch                   =     2.9998</span><br><span class="line">  eval_accuracy           =     0.6514</span><br><span class="line">  eval_loss               =     1.5619</span><br><span class="line">  eval_runtime            = 0:00:49.51</span><br><span class="line">  eval_samples_per_second =    226.692</span><br><span class="line">  eval_steps_per_second   =     37.789</span><br><span class="line">  num_input_tokens_seen   =  123942712</span><br><span class="line">[INFO|modelcard.py:449] 2024-07-16 11:52:26,802 &gt;&gt; Dropping the following result as it does not have all the necessary fields:</span><br><span class="line">&#123;&#x27;task&#x27;: &#123;&#x27;name&#x27;: &#x27;Causal Language Modeling&#x27;, &#x27;type&#x27;: &#x27;text-generation&#x27;&#125;, &#x27;metrics&#x27;: [&#123;&#x27;name&#x27;: &#x27;Accuracy&#x27;, &#x27;type&#x27;: &#x27;accuracy&#x27;, &#x27;value&#x27;: 0.6513998945712532&#125;]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">conda create -n opencompass python=3.10 -y</span><br><span class="line">conda activate opencompass</span><br><span class="line"></span><br><span class="line">git clone https://github.com/open-compass/opencompass opencompass</span><br><span class="line">cd opencompass</span><br><span class="line"></span><br><span class="line">在opencompass/requirements/runtime.txt的最后⼀⾏添加ai2-olmo</span><br><span class="line"></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -e .</span><br><span class="line"></span><br><span class="line">cd opencompass</span><br><span class="line">wget https://github.com/opencompass/opencompass/releases/download/0.2.2.rc1/OpenCompassData-core-20240207.zip</span><br><span class="line"></span><br><span class="line">unzip OpenCompassData-core-20240207.zip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#ModuleNotFoundError: No module named &#x27;human_eval&#x27;</span><br><span class="line">git clone git@github.com:open-compass/human-eval.git</span><br><span class="line">cd human-eval &amp;&amp; pip install -e .</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup llamafactory-cli train examples/train_full/llama3_full_sft_ds3_v2_step1.yaml &gt; /LLaMA-Factory/examples/train_full/script_output.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<h2 id="SFT数据样本量"><a href="#SFT数据样本量" class="headerlink" title="SFT数据样本量"></a>SFT数据样本量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup llamafactory-cli train examples/train_full/llama3_full_sft_ds3_v4.yaml &gt; /home/luchenhao/LLaMA-Factory/examples/train_full/script_output.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ERROR: pip&#x27;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span><br><span class="line">llava 1.2.2.post1 requires tokenizers==0.15.1, but you have tokenizers 0.19.1 which is incompatible.</span><br><span class="line">llava 1.2.2.post1 requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.</span><br><span class="line">llava 1.2.2.post1 requires torchvision==0.16.2, but you have torchvision 0.18.1 which is incompatible.</span><br><span class="line">llava 1.2.2.post1 requires transformers==4.37.2, but you have transformers 4.43.2 which is incompatible.</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python3 -m llava.serve.controller --host 0.0.0.0 --port 20000</span><br><span class="line"></span><br><span class="line">python3 -m llava.serve.gradio_web_server --controller http://localhost:20000 --model-list-mode reload --share</span><br><span class="line"></span><br><span class="line">python3 -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:20000 --port 40000 --worker http://localhost:40000 --model-path /mnt/LLM-pretrain-dataset/luchenhao/table_llava/checkpoints/llava-v1.5-1b-sft-with-table/checkpoint-7500 --load-4bit</span><br><span class="line"></span><br><span class="line">python3 -m llava.serve.model_worker --host 10.5.30.42 --controller http://localhost:8000 --port 8888 --worker http://localhost:8888 --model-path /mnt/LLM-pretrain-dataset/luchenhao/table_llava/checkpoints/llava-v1.5-1b-sft-with-table/checkpoint-7500 --load-4bit</span><br><span class="line"></span><br><span class="line">python3 -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:20000 --port 40000 --worker http://localhost:40000 --model-path /mnt/LLM-pretrain-dataset/luchenhao/table_llava/checkpoints/llava-v1.5-1b-sft-with-table/checkpoint-7500 --load-4bit</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>|  | sub-groups of the agri-food industry   | eastern ontario | northern ontario        |\n||————————————————————|————————-|————————————-|———————-|\n|  | percent                                |\n|  | input and service supply               | 2.9             | 2.1                     | 2.9           | 1.3  |\n|  | food, beverage, and tobacco processing | 9.7             | 6.0                     | 3.0           | 3.3  |\n|  | food retail and wholesale              | 35.3            | 31.3                    | 39.1          | 37.3 |\n|  | food service                           | 52.1            | 60.6                    | 55.0          | 58.1 |\n”写一段代码讲这里面的“| xxx        |</p>
<p>“Table:\n\n| Year | Title | Role | Channel |\n| —- | —- | —- | —- |\n| 2015 | Kuch Toh Hai Tere Mere Darmiyaan | Sanjana Kapoor | Star Plus |\n| 2016 | Kuch Rang Pyar Ke Aise Bhi | Khushi | Sony TV |\n| 2016 | Gangaa | Aashi Jhaa | &amp;TV |\n| 2017 | Iss Pyaar Ko Kya Naam Doon 3 | Meghna Narayan Vashishth | Star Plus |\n| 2017–18 | Tu Aashiqui | Richa Dhanrajgir | Colors TV |\n| 2019 | Laal Ishq | Pernia | &amp;TV |\n| 2019 | Vikram Betaal Ki Rahasya Gatha | Rukmani/Kashi | &amp;TV |\n| 2019 | Shaadi Ke Siyape | Dua | &amp;TV |\n\nConduct table question answering task based on the given table about ‘Shagun Sharma’ with the table title ‘Television’.\nWhat TV shows was Shagun Sharma seen in 2019?”,</p>
<h2 id="镜像打包"><a href="#镜像打包" class="headerlink" title="镜像打包"></a>镜像打包</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">docker create --name LLamaFactory --gpus all -v /mnt/nas_v2:/mnt -e SCRATCH_DIR=/mnt/nas_v2/LLM-pretrain-dataset/luchenhao/tmp -it nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker create --name LLamaFactory --shm-size=32g --gpus all -v /mnt_llm/luchenhao:/mnt_llm/luchenhao -e SCRATCH_DIR=/mnt_llm/luchenhao/tmp -it nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line">docker start -i LLamaFactory</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cp /etc/apt/sources.list /etc/apt/sources.list.1</span><br><span class="line">sed -i &#x27;s|http://archive.ubuntu.com/ubuntu/|http://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g&#x27; /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">apt-get update</span><br><span class="line">apt-get install python3.10 python3-pip git</span><br><span class="line">pip install --upgrade pip </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd /mnt/nas_v2/LLM-pretrain-dataset/luchenhao/LLaMA-Factory</span><br><span class="line">pip install --no-cache-dir -e &quot;.[torch,metrics]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">docker exec -it -w /mnt/LLM-pretrain-dataset/luchenhao/LLaMA-Factory LLamaFactory llamafactory-cli train examples/train_full/llama3_full_sft_ds3_v6.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker exec -it -w /mnt/LLM-pretrain-dataset/luchenhao/LLaMA-Factory LLamaFactory nohup llamafactory-cli train examples/train_full/llama3_full_sft_ds3_v6.yaml &gt; examples/train_full/script_output9.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name LLamaFactory1 --gpus all --hostname=LLamaFactory --shm-size=32g -v /mnt/nas_v2:/mnt/nas_v2 -w /mnt/nas_v2/LLM-pretrain-dataset/luchenhao/LLaMA-Factory nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"> </span><br><span class="line">docker exec -it LLamaFactory llamafactory-cli train examples/train_full/llama3_full_sft_ds3_v6.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -itd --name LLaVA --gpus all --hostname=LLaVA --shm-size=64g -v /mnt/nas_v2:/mnt/nas_v2 nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line">cp /etc/apt/sources.list /etc/apt/sources.list.1</span><br><span class="line">sed -i &#x27;s|http://archive.ubuntu.com/ubuntu/|http://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g&#x27; /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">apt-get update</span><br><span class="line">apt-get install python3.10 python3-pip</span><br><span class="line">pip install --upgrade pip </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd /mnt/nas_v2/LLM-pretrain-dataset/luchenhao/LLaVA</span><br><span class="line">pip install --no-cache-dir -e . -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --no-cache-dir -e &quot;.[train]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --no-cache-dir  flash-attn --no-build-isolation -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">docker exec -it llava sh scripts/v1_5/table_llava_scripts/pretrain_table_llava.sh</span><br></pre></td></tr></table></figure>
<h2 id="RSPrompter推理"><a href="#RSPrompter推理" class="headerlink" title="RSPrompter推理"></a>RSPrompter推理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">docker pull nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line">docker create --name RSPrompter_Lch --shm-size=64g --gpus all -v /mnt_llm/RSPrompter:/mnt_llm/RSPrompter -it nvidia/cuda:12.1.0-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line">docker start -i RSPrompter_Lch</span><br><span class="line"></span><br><span class="line">cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">sed -i &#x27;s|http://archive.ubuntu.com/ubuntu/|http://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g&#x27; /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">apt-get update</span><br><span class="line">apt-get install locales</span><br><span class="line">locale-gen en_US.UTF-8</span><br><span class="line">apt-get install vim</span><br><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line">export LANG=en_US.UTF-8</span><br><span class="line">export LC_CTYPE=en_US.UTF-8</span><br><span class="line">source ~/.bashrc</span><br><span class="line"></span><br><span class="line">apt-get install python3.10 python3-pip git</span><br><span class="line">pip install --upgrade pip </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd /mnt_llm/hzh/LLaVA/</span><br><span class="line">pip install --no-cache-dir -e . -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --no-cache-dir -e &quot;.[train]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --no-cache-dir  flash-attn --no-build-isolation -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<h3 id="检查磁盘挂载情况"><a href="#检查磁盘挂载情况" class="headerlink" title="检查磁盘挂载情况"></a>检查磁盘挂载情况</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br><span class="line">du -h --max-depth=1 | sort -h</span><br><span class="line">du -sh * | sort -h</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="安装语言环境"><a href="#安装语言环境" class="headerlink" title="安装语言环境"></a>安装语言环境</h2><p>这个错误提示表明系统尝试设置 <code>LC_CTYPE</code> 为 <code>en_US.UTF-8</code>，但是系统没有找到或无法使用这个语言环境。可以通过以下步骤来修复这个问题：</p>
<h3 id="1-重新生成-en-US-UTF-8-语言环境"><a href="#1-重新生成-en-US-UTF-8-语言环境" class="headerlink" title="1. 重新生成 en_US.UTF-8 语言环境"></a>1. 重新生成 <code>en_US.UTF-8</code> 语言环境</h3><p>首先，确保你有权限使用 <code>locale-gen</code> 命令。如果你的系统缺少这个工具，可以通过安装 <code>locales</code> 包来修复。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install locales</span><br></pre></td></tr></table></figure>
<p>然后，生成 <code>en_US.UTF-8</code> 语言环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo locale-gen en_US.UTF-8</span><br></pre></td></tr></table></figure>
<p>最后，更新系统的语言环境设置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-locale LANG=en_US.UTF-8</span><br></pre></td></tr></table></figure>
<h3 id="2-验证并应用更改"><a href="#2-验证并应用更改" class="headerlink" title="2. 验证并应用更改"></a>2. 验证并应用更改</h3><p>重启你的终端或执行以下命令使更改生效：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/default/locale</span><br></pre></td></tr></table></figure>
<h3 id="3-检查语言环境设置"><a href="#3-检查语言环境设置" class="headerlink" title="3. 检查语言环境设置"></a>3. 检查语言环境设置</h3><p>你可以使用以下命令检查当前的语言环境设置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">locale</span><br></pre></td></tr></table></figure>
<p>如果上述步骤无法解决问题，确保 <code>/etc/locale.gen</code> 文件中包含 <code>en_US.UTF-8 UTF-8</code> 这一行，并运行 <code>sudo locale-gen</code> 来重新生成语言环境。</p>
<h3 id="4-进一步调试"><a href="#4-进一步调试" class="headerlink" title="4. 进一步调试"></a>4. 进一步调试</h3><p>如果问题仍然存在，可以尝试手动设置语言环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LC_ALL=en_US.UTF-8</span><br><span class="line"><span class="built_in">export</span> LANG=en_US.UTF-8</span><br><span class="line"><span class="built_in">export</span> LANGUAGE=en_US.UTF-8</span><br></pre></td></tr></table></figure>
<p>这些命令在当前会话中临时生效，确保你的 <code>.bashrc</code> 或 <code>.zshrc</code> 文件中正确设置了这些环境变量。</p>
<h2 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apt-get install zsh </span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line">apt-get install curl</span><br><span class="line">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;</span><br><span class="line"></span><br><span class="line">1. ys-conda样式要复制一份到themes里面</span><br><span class="line">2. 复制以前的zshrc</span><br><span class="line">3. git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions</span><br><span class="line">4. git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting </span><br><span class="line">（https://zhuanlan.zhihu.com/p/441676276）</span><br><span class="line">（https://juejin.cn/post/7279720525362315264）</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="安装代理"><a href="#安装代理" class="headerlink" title="安装代理"></a>安装代理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://blog.myxuechao.com/post/36#%E5%9B%9B%E3%80%81%E9%85%8D%E7%BD%AEClash%E5%8F%AF%E8%A7%86%E5%8C%96%E9%9D%A2%E6%9D%BF</span><br><span class="line">https://ikuuu.pw/user/tutorial?os=linux&amp;client=clash##</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Luke</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/">http://example.com/2024/06/29/种子班笔记/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Luke's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar1.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/06/11/Graph%20RAG%20%E4%B8%8E%20Text2Cypher%20%E7%9A%84%E5%AF%B9%E6%AF%94/" title=""><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info"></div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar1.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Luke</div><div class="author-info__description">See the world, find yourself.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xxxxx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码随想录算法题，持续更新中！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-06-29"><span class="toc-number">1.</span> <span class="toc-text">2024&#x2F;06&#x2F;29</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">1.1.</span> <span class="toc-text">数据准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dedupelicate"><span class="toc-number">1.1.1.</span> <span class="toc-text">dedupelicate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-07-02"><span class="toc-number">1.2.</span> <span class="toc-text">2024&#x2F;07&#x2F;02</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#docker%E9%85%8D%E7%BD%AE"><span class="toc-number">1.3.</span> <span class="toc-text">docker配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">1.4.</span> <span class="toc-text">数据处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%AD%E6%96%99%E5%88%86%E7%B1%BB%E6%83%85%E5%86%B5%E4%B8%8B%E8%BF%9B%E8%A1%8C%E8%AF%8D%E5%85%83%E5%8C%96"><span class="toc-number">1.5.</span> <span class="toc-text">语料分类情况下进行词元化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%AD%E6%96%99%E4%B8%8D%E5%88%86%E7%B1%BB%E6%83%85%E5%86%B5%E4%B8%8B%E8%BF%9B%E8%A1%8C%E8%AF%8D%E5%85%83%E5%8C%96"><span class="toc-number">1.6.</span> <span class="toc-text">语料不分类情况下进行词元化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dolma-Pipeline"><span class="toc-number">1.7.</span> <span class="toc-text">Dolma Pipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD-python-reformat-py"><span class="toc-number">1.8.</span> <span class="toc-text">数据下载 python &#x2F;reformat.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%EF%BC%88%E5%85%B3%E9%94%AEkey%E6%B7%BB%E5%8A%A0%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%BAJsonl%E3%80%81%E5%8E%8B%E7%BC%A9%EF%BC%89"><span class="toc-number">1.9.</span> <span class="toc-text">数据转换（关键key添加、转换为Jsonl、压缩）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tagger"><span class="toc-number">1.10.</span> <span class="toc-text">Tagger</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deduplicate"><span class="toc-number">1.11.</span> <span class="toc-text">Deduplicate</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mixer"><span class="toc-number">1.12.</span> <span class="toc-text">Mixer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#JSONPath%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%A7%A3%E6%9E%90"><span class="toc-number">1.12.1.</span> <span class="toc-text">JSONPath表达式解析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%AE%B5%E8%A7%A3%E9%87%8A"><span class="toc-number">1.12.1.1.</span> <span class="toc-text">分段解释</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E8%A7%A3%E9%87%8A"><span class="toc-number">1.12.1.2.</span> <span class="toc-text">综合解释</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.12.2.</span> <span class="toc-text">示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.12.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tokenizer"><span class="toc-number">1.13.</span> <span class="toc-text">Tokenizer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E8%AF%8D%E5%99%A8%E8%A7%A3%E7%A0%81%E6%A0%A1%E9%AA%8C"><span class="toc-number">1.14.</span> <span class="toc-text">分词器解码校验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tar%E6%96%87%E4%BB%B6%E8%A7%A3%E5%8E%8B"><span class="toc-number">1.15.</span> <span class="toc-text">tar文件解压</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tar%E6%96%87%E4%BB%B6%E5%88%87%E5%88%86"><span class="toc-number">1.16.</span> <span class="toc-text">tar文件切分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sample"><span class="toc-number">1.17.</span> <span class="toc-text">sample</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#token%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="toc-number">1.18.</span> <span class="toc-text">token量计算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">1.18.1.</span> <span class="toc-text">估算过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.18.2.</span> <span class="toc-text">计算示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">1.18.3.</span> <span class="toc-text">结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">1.18.4.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#token%E9%87%8F%E5%92%8Cnpy%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.19.</span> <span class="toc-text">token量和npy文件大小的转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-int32-%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8-tokens"><span class="toc-number">1.19.1.</span> <span class="toc-text">使用 int32 类型存储 tokens</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%EF%BC%9A"><span class="toc-number">1.19.1.1.</span> <span class="toc-text">计算公式：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E8%AE%A1%E7%AE%97%EF%BC%9A"><span class="toc-number">1.19.1.2.</span> <span class="toc-text">实际计算：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-int64-%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8-tokens"><span class="toc-number">1.19.2.</span> <span class="toc-text">使用 int64 类型存储 tokens</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%EF%BC%9A-1"><span class="toc-number">1.19.2.1.</span> <span class="toc-text">计算公式：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E8%AE%A1%E7%AE%97%EF%BC%9A-1"><span class="toc-number">1.19.2.2.</span> <span class="toc-text">实际计算：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.19.3.</span> <span class="toc-text">完整代码示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C"><span class="toc-number">1.19.4.</span> <span class="toc-text">输出结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-1"><span class="toc-number">1.19.5.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C"><span class="toc-number">1.20.</span> <span class="toc-text">运行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C-Data-Parallel-DP"><span class="toc-number">1.20.1.</span> <span class="toc-text">数据并行 (Data Parallel, DP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C-Model-Parallel-MP"><span class="toc-number">1.20.2.</span> <span class="toc-text">模型并行 (Model Parallel, MP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C-Pipeline-Parallel-PP"><span class="toc-number">1.20.3.</span> <span class="toc-text">流水线并行 (Pipeline Parallel, PP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E7%89%87%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C-Fully-Sharded-Data-Parallel-FSDP"><span class="toc-number">1.20.4.</span> <span class="toc-text">完全分片数据并行 (Fully Sharded Data Parallel, FSDP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E5%8F%8A%E5%85%B3%E7%B3%BB"><span class="toc-number">1.20.5.</span> <span class="toc-text">总结及关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SFT"><span class="toc-number">1.21.</span> <span class="toc-text">SFT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SFT%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%AC%E9%87%8F"><span class="toc-number">1.22.</span> <span class="toc-text">SFT数据样本量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%95%9C%E5%83%8F%E6%89%93%E5%8C%85"><span class="toc-number">1.23.</span> <span class="toc-text">镜像打包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RSPrompter%E6%8E%A8%E7%90%86"><span class="toc-number">1.24.</span> <span class="toc-text">RSPrompter推理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E6%83%85%E5%86%B5"><span class="toc-number">1.24.1.</span> <span class="toc-text">检查磁盘挂载情况</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83"><span class="toc-number">1.25.</span> <span class="toc-text">安装语言环境</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%87%8D%E6%96%B0%E7%94%9F%E6%88%90-en-US-UTF-8-%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83"><span class="toc-number">1.25.1.</span> <span class="toc-text">1. 重新生成 en_US.UTF-8 语言环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%AA%8C%E8%AF%81%E5%B9%B6%E5%BA%94%E7%94%A8%E6%9B%B4%E6%94%B9"><span class="toc-number">1.25.2.</span> <span class="toc-text">2. 验证并应用更改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A3%80%E6%9F%A5%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.25.3.</span> <span class="toc-text">3. 检查语言环境设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%BF%9B%E4%B8%80%E6%AD%A5%E8%B0%83%E8%AF%95"><span class="toc-number">1.25.4.</span> <span class="toc-text">4. 进一步调试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85zsh"><span class="toc-number">1.26.</span> <span class="toc-text">安装zsh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E4%BB%A3%E7%90%86"><span class="toc-number">1.27.</span> <span class="toc-text">安装代理</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/29/%E7%A7%8D%E5%AD%90%E7%8F%AD%E7%AC%94%E8%AE%B0/" title="无题">无题</a><time datetime="2024-06-29T09:21:38.427Z" title="发表于 2024-06-29 17:21:38">2024-06-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/11/Graph%20RAG%20%E4%B8%8E%20Text2Cypher%20%E7%9A%84%E5%AF%B9%E6%AF%94/" title="无题">无题</a><time datetime="2024-06-11T08:14:20.029Z" title="发表于 2024-06-11 16:14:20">2024-06-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/05/RAG%E9%9D%A2%E8%AF%95%E9%A2%98/" title="无题">无题</a><time datetime="2024-06-05T02:05:58.294Z" title="发表于 2024-06-05 10:05:58">2024-06-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/11/Self-RAG/" title="无题">无题</a><time datetime="2024-04-11T06:22:25.781Z" title="发表于 2024-04-11 14:22:25">2024-04-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/11/C-RAG/" title="无题">无题</a><time datetime="2024-04-11T02:39:42.121Z" title="发表于 2024-04-11 10:39:42">2024-04-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Luke</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>